{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Static Model Pruning with BERT on SQUAD Dataset"
      ],
      "metadata": {
        "id": "1bgFOjwiJIDY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F25s5zYdloxz",
        "outputId": "80ed5929-c834-4940-ccd1-1cd5ccbcceda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Mounting the Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8w1Fs9is3vy"
      },
      "outputs": [],
      "source": [
        "#Installing all the requirements\n",
        "!pip install transformers==4.17.0 datasets==1.17.0 huggingface-hub==0.2.1 tokenizers==0.11.6 scipy==1.7.3 scikit-learn==1.0.2 wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb-sDN7XoTp9",
        "outputId": "f4bb75e7-26c5-434b-cf04-893bd9b9ee7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/NLP-PROJECT/squad_teacher_model.zip\n",
            "   creating: /content/squad_teacher_model/\n",
            "  inflating: /content/squad_teacher_model/rng_state.pth  \n",
            "  inflating: /content/squad_teacher_model/tokenizer_config.json  \n",
            "  inflating: /content/squad_teacher_model/special_tokens_map.json  \n",
            "  inflating: /content/squad_teacher_model/config.json  \n",
            "  inflating: /content/squad_teacher_model/scheduler.pt  \n",
            "  inflating: /content/squad_teacher_model/tokenizer.json  \n",
            "  inflating: /content/squad_teacher_model/training_args.bin  \n",
            "  inflating: /content/squad_teacher_model/vocab.txt  \n",
            "  inflating: /content/squad_teacher_model/pytorch_model.bin  Archive:  /content/drive/MyDrive/NLP-PROJECT/Ensemble-ALBERT-on-SQuAD-2.0-master.zip\n",
            "86567fe3e90de8fb2139ff4ec839b34d653d69a4\n",
            "   creating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/\n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/.gitattributes  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/LICENSE  \n",
            " extracting: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/README.md  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/args.py  \n",
            "   creating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/data/\n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/data/dev_gold_dict.json  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/data/xxlarge_123_dev.pickle  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/data/xxlarge_123_test.pickle  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/data/xxlarge_224_dev.pickle  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/data/xxlarge_224_test.pickle  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/data_predictions.py  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/data_preprocess.py  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/ensemble.py  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/ensemble_2.py  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/environment.yml  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/layers.py  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/models.py  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/models_2.py  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/setup.py  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/test.py  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/train.py  \n",
            "  inflating: /content/Ensemble-ALBERT-on-SQuAD-2.0-master/util.py  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "zip_dir = '/content/drive/MyDrive/NLP-PROJECT/'\n",
        "\n",
        "for file in os.listdir(zip_dir):\n",
        "    if file.endswith('.zip'):\n",
        "        file_path = os.path.join(zip_dir, file)\n",
        "        !unzip {file_path} -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37gYGfk66FJz",
        "outputId": "d51b1558-4889-46c0-8fd7-047e44992030"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "squad_teacher_model.zip: Zip archive data, at least v1.0 to extract, compression method=store\n"
          ]
        }
      ],
      "source": [
        "!file squad_teacher_model.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YPmKF_I4uyI",
        "outputId": "ceb7a931-9067-4ebf-9d4b-27c62956fab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  squad_teacher_model.zip\n",
            "   creating: squad_teacher_model/\n",
            "  inflating: squad_teacher_model/rng_state.pth  \n",
            "  inflating: squad_teacher_model/tokenizer_config.json  \n",
            "  inflating: squad_teacher_model/special_tokens_map.json  \n",
            "  inflating: squad_teacher_model/config.json  \n",
            "  inflating: squad_teacher_model/scheduler.pt  \n",
            "  inflating: squad_teacher_model/tokenizer.json  \n",
            "  inflating: squad_teacher_model/training_args.bin  \n",
            "  inflating: squad_teacher_model/vocab.txt  \n",
            "  inflating: squad_teacher_model/pytorch_model.bin  \n",
            "  inflating: squad_teacher_model/trainer_state.json  \n"
          ]
        }
      ],
      "source": [
        "!unzip squad_teacher_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lr1JkOQSr69p"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/kongds/SMP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2I4oIAezv_w"
      },
      "outputs": [],
      "source": [
        "!pip install wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rS_PTR-z4uh"
      },
      "outputs": [],
      "source": [
        "!wandb login\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQtnTUHN98dn"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.8.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJrkzRPRyKLL"
      },
      "outputs": [],
      "source": [
        "!apt-get install bc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R63Zi6QOyklp"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y protobuf\n",
        "\n",
        "# Install compatible versions\n",
        "!pip install protobuf==3.20.3\n",
        "\n",
        "# Reinstall transformers and datasets to ensure compatibility\n",
        "!pip install transformers==4.17.0 datasets==1.17.0\n",
        "\n",
        "# Restart the runtime\n",
        "import os\n",
        "os._exit(00)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "enDfujuHszJo",
        "outputId": "77adf943-a25c-4adc-b3d7-a07213205be9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 100 lines.\u001b[0m\n",
            " 87% 9203/10570 [00:29<00:04, 330.05it/s]\u001b[A\n",
            " 87% 9237/10570 [00:29<00:04, 331.49it/s]\u001b[A\n",
            " 88% 9271/10570 [00:29<00:03, 332.66it/s]\u001b[A\n",
            " 88% 9305/10570 [00:29<00:03, 331.95it/s]\u001b[A\n",
            " 88% 9339/10570 [00:29<00:03, 329.20it/s]\u001b[A\n",
            " 89% 9372/10570 [00:29<00:03, 323.41it/s]\u001b[A\n",
            " 89% 9405/10570 [00:29<00:03, 324.07it/s]\u001b[A\n",
            " 89% 9438/10570 [00:29<00:03, 325.51it/s]\u001b[A\n",
            " 90% 9471/10570 [00:29<00:03, 322.11it/s]\u001b[A\n",
            " 90% 9504/10570 [00:29<00:03, 323.60it/s]\u001b[A\n",
            " 90% 9538/10570 [00:30<00:03, 328.22it/s]\u001b[A\n",
            " 91% 9572/10570 [00:30<00:03, 330.06it/s]\u001b[A\n",
            " 91% 9606/10570 [00:30<00:02, 329.12it/s]\u001b[A\n",
            " 91% 9640/10570 [00:30<00:02, 330.21it/s]\u001b[A\n",
            " 92% 9674/10570 [00:30<00:02, 331.89it/s]\u001b[A\n",
            " 92% 9709/10570 [00:30<00:02, 335.19it/s]\u001b[A\n",
            " 92% 9744/10570 [00:30<00:02, 337.18it/s]\u001b[A\n",
            " 93% 9778/10570 [00:30<00:02, 335.80it/s]\u001b[A\n",
            " 93% 9812/10570 [00:30<00:02, 334.69it/s]\u001b[A\n",
            " 93% 9846/10570 [00:30<00:02, 328.99it/s]\u001b[A\n",
            " 93% 9880/10570 [00:31<00:02, 331.30it/s]\u001b[A\n",
            " 94% 9914/10570 [00:31<00:01, 329.15it/s]\u001b[A\n",
            " 94% 9948/10570 [00:31<00:01, 331.73it/s]\u001b[A\n",
            " 94% 9982/10570 [00:31<00:01, 326.32it/s]\u001b[A\n",
            " 95% 10015/10570 [00:31<00:01, 324.61it/s]\u001b[A\n",
            " 95% 10048/10570 [00:31<00:01, 325.22it/s]\u001b[A\n",
            " 95% 10081/10570 [00:31<00:01, 314.24it/s]\u001b[A\n",
            " 96% 10113/10570 [00:31<00:01, 311.63it/s]\u001b[A\n",
            " 96% 10145/10570 [00:31<00:01, 300.91it/s]\u001b[A\n",
            " 96% 10176/10570 [00:32<00:01, 294.87it/s]\u001b[A\n",
            " 97% 10210/10570 [00:32<00:01, 306.36it/s]\u001b[A\n",
            " 97% 10244/10570 [00:32<00:01, 315.54it/s]\u001b[A\n",
            " 97% 10277/10570 [00:32<00:00, 318.79it/s]\u001b[A\n",
            " 98% 10311/10570 [00:32<00:00, 324.21it/s]\u001b[A\n",
            " 98% 10345/10570 [00:32<00:00, 327.64it/s]\u001b[A\n",
            " 98% 10378/10570 [00:32<00:00, 327.82it/s]\u001b[A\n",
            " 99% 10412/10570 [00:32<00:00, 328.69it/s]\u001b[A\n",
            " 99% 10445/10570 [00:32<00:00, 328.75it/s]\u001b[A\n",
            " 99% 10478/10570 [00:32<00:00, 326.05it/s]\u001b[A\n",
            " 99% 10512/10570 [00:33<00:00, 327.66it/s]\u001b[A\n",
            "100% 10570/10570 [00:33<00:00, 318.37it/s]\n",
            "11/30/2024 09:44:59 - INFO - utils_qa - Saving predictions to models/squad_0.50_kd_mag/eval_predictions.json.\n",
            "11/30/2024 09:44:59 - INFO - utils_qa - Saving nbest_preds to models/squad_0.50_kd_mag/eval_nbest_predictions.json.\n",
            "11/30/2024 09:45:04 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad/default/default_experiment-1-0.arrow\n",
            "100% 337/337 [02:10<00:00,  2.57it/s]\n",
            "***** eval metrics *****\n",
            "  epoch            =    10.0\n",
            "  eval_exact_match = 82.7436\n",
            "  eval_f1          = 89.6668\n",
            "  eval_samples     =   10784\n",
            "[INFO|modelcard.py:460] 2024-11-30 09:45:04,624 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Question Answering', 'type': 'question-answering'}, 'dataset': {'name': 'squad', 'type': 'squad', 'args': 'plain_text'}}\n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33msquad_0.50_kd_mag\u001b[0m at: \u001b[34mhttps://wandb.ai/nk3696-new-york-university/MP_SQUAD/runs/zcso1s3c\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241130_023628-zcso1s3c/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd /content/SMP\n",
        "!bash run_squad.sh squad_0.50_kd_mag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pQxLpis3q9g"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/SMP /content/drive/My\\ Drive/NLP-PROJECT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFqG2qdG6ojh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
